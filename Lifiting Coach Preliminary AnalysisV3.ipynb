{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lifting coach preliminary analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "#%matplotlib inline\n",
    "# Import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import statistics\n",
    "from scipy import stats\n",
    "import itertools\n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The sliding_window function uses the inputs data, events, an epoch length (seconds), overlap (percentage of overlap) and \n",
    "sample rate as a way to generate a dataframe for machine learning.\n",
    "\"\"\"\n",
    "def sliding_Window(data, events, epoch_Length, overlap, sample_Rate):\n",
    "    \n",
    "    # Trial information\n",
    "    data_Header = data.columns\n",
    "    number_Of_Samples = len(events) \n",
    "    trial_Length = len(events)/sample_Rate\n",
    "    slide = epoch_Length - (epoch_Length*overlap)\n",
    "    \n",
    "    # Define Start and Stop\n",
    "    n = round(((number_Of_Samples - epoch_Length*sample_Rate)/(slide*sample_Rate)),0)-1\n",
    "    start = [round(x*slide, 2) for x in range(int(n))]\n",
    "    stop = [round(x*slide+epoch_Length, 2) for x in range(int(n))]\n",
    "    \n",
    "    # Define Mean and Stardard Deviation of data during an epoch\n",
    "    mean_Data = [[] for j in range(len(data.columns))]\n",
    "    mean_Names = ['mean_' + x for x in data_Header]\n",
    "    std_Data = [[] for k in range(len(data.columns))]\n",
    "    std_Names = ['std_' + x for x in data_Header]\n",
    "    \n",
    "    for item in range(len(data.columns)):\n",
    "        for i in range(len(start)):\n",
    "            current_Mean = data.iloc[int(start[i]*sample_Rate):int(stop[i]*sample_Rate), item].mean()\n",
    "            current_STD = data.iloc[int(start[i]*sample_Rate):int(stop[i]*sample_Rate), item].std()\n",
    "            mean_Data[item].append(current_Mean)\n",
    "            std_Data[item].append(current_STD)\n",
    "    \n",
    "    # Create dataframes for the data\n",
    "    start_D = pd.DataFrame(start)\n",
    "    start_D.columns = ['Start']\n",
    "    stop_D = pd.DataFrame(stop)\n",
    "    stop_D.columns = ['Stop']\n",
    "    \n",
    "    mean_D = pd.DataFrame(mean_Data)\n",
    "    mean_D = mean_D.transpose()\n",
    "    mean_D.columns = mean_Names\n",
    "\n",
    "    std_D = pd.DataFrame(std_Data)\n",
    "    std_D = std_D.transpose()\n",
    "    std_D.columns = std_Names \n",
    "\n",
    "    revised_Data = pd.concat([start_D, stop_D, mean_D, std_D], axis=1)\n",
    "    return revised_Data\n",
    "\n",
    "#j = sliding_Window(Lift_Data, events, 1.5, 0.9, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_Window_Events(events, epoch_Length, overlap, sample_Rate):\n",
    "    number_Of_Samples = len(events) \n",
    "    trial_Length = len(events)/sample_Rate\n",
    "    slide = epoch_Length - (epoch_Length*overlap)\n",
    "    \n",
    "    # Define Start and Stop\n",
    "    n = round(((number_Of_Samples - epoch_Length*sample_Rate)/(slide*sample_Rate)),0)-1\n",
    "    start = [round(x*slide, 2) for x in range(int(n))]\n",
    "    stop = [round(x*slide+epoch_Length, 2) for x in range(int(n))]\n",
    "    \n",
    "    revised_Events = []\n",
    "    for i in range(len(start)):\n",
    "        current_Epoch = events.iloc[int(start[i]*sample_Rate):int(stop[i]*sample_Rate)]\n",
    "        current_Event = np.bincount(current_Epoch).argmax()\n",
    "        revised_Events.append(current_Event)\n",
    "    \n",
    "    \n",
    "    event_Data = pd.DataFrame(revised_Events)\n",
    "    event_Data.columns = ['Events']\n",
    "    return event_Data\n",
    "    \n",
    "#k = sliding_Window_Events(events, 1.5, 0.9, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_Event_Array(lengths, overlaps, list_Events, algorithms, sample_Rate):\n",
    "    # Define the matrix dimensions\n",
    "    maxO = max(overlaps)\n",
    "    minL = min(test_Lengths)\n",
    "    slide = minL - (minL*maxO)\n",
    "    \n",
    "    # Define Start\n",
    "    number_Of_Samples = len(events)\n",
    "    n = round(((number_Of_Samples - minL*sample_Rate)/(slide*sample_Rate)),0)-1\n",
    "    start = [round(x*slide, 2) for x in range(int(n))]\n",
    "\n",
    "    \n",
    "    generated_List = []\n",
    "    # Create an array of zeros\n",
    "    for current_Lengths in lengths:\n",
    "        for current_Overlap in overlaps:\n",
    "            for current_List in list_Events:\n",
    "                for current_Algorithms in algorithms:\n",
    "                    name = [current_List, current_Algorithms, str(current_Lengths), str(current_Overlap)]\n",
    "                    current_Column = '_'.join(name)\n",
    "                    generated_List.append(current_Column)\n",
    "    feature_List = ['Start','Tested_Epochs', list_Events[0], list_Events[1], list_Events[2]] + generated_List\n",
    "    building_Array = pd.DataFrame(0, index=np.arange(len(start)), columns=feature_List)\n",
    "    building_Array['Start'] = start\n",
    "    return building_Array\n",
    "\n",
    "# test_Lengths = [1.5, 2.0, 2.5, 3.0]\n",
    "# overlaps = [0.5, 0.9]\n",
    "# list_Events = ['Stand_Free', 'Lift_Squat', 'Lower_Squat']\n",
    "# algorithms = ['LDA', 'KNN', 'NB', 'QDA', 'LR']\n",
    "# tt = initialize_Event_Array(test_Lengths, overlaps, list_Events, algorithms, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_Events(events):\n",
    "    # 1-Stand-Free, 3-Lift-Squat, 5-Lower-Squat\n",
    "    event_Data = pd.get_dummies(events['Events'])\n",
    "    event_Data.columns = ['Stand_Free', 'Lift_Squat', 'Lower_Squat']\n",
    "    return event_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_To_Time(index, my_Epoch_Length, my_Overlap, events):\n",
    "    number_Of_Samples = len(events) \n",
    "    trial_Length = len(events)/sample_Rate\n",
    "    slide = my_Epoch_Length - (my_Epoch_Length*my_Overlap)\n",
    "    \n",
    "    # Define Start and Stop\n",
    "    n = round(((number_Of_Samples - my_Epoch_Length*sample_Rate)/(slide*sample_Rate)),0)-1\n",
    "    start = [round(x*slide, 2) for x in range(int(n))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into python \n",
    "header = ['EventActNumNoZero', 'FP34okNoZero', 'FP34ok_ff_LoadOnlyNoZero', 'aLx','aLy','aLz', 'aRx','aRy','aRz']\n",
    "Lift_Data = pd.read_csv(\"D:/DissertationNotebooks/LiftingCoach/Revised_Lifting_v3.csv\")\n",
    "Lift_Data.columns = header\n",
    "# Sample rate 120 hz\n",
    "data = Lift_Data[Lift_Data.columns[1:]]\n",
    "events = Lift_Data['EventActNumNoZero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventActNumNoZero</th>\n",
       "      <th>FP34okNoZero</th>\n",
       "      <th>FP34ok_ff_LoadOnlyNoZero</th>\n",
       "      <th>aLx</th>\n",
       "      <th>aLy</th>\n",
       "      <th>aLz</th>\n",
       "      <th>aRx</th>\n",
       "      <th>aRy</th>\n",
       "      <th>aRz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>984.18</td>\n",
       "      <td>1.06970</td>\n",
       "      <td>0.1944</td>\n",
       "      <td>-0.0576</td>\n",
       "      <td>-0.0684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>984.84</td>\n",
       "      <td>0.92797</td>\n",
       "      <td>-0.0720</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>-0.2808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>985.28</td>\n",
       "      <td>0.77270</td>\n",
       "      <td>-0.1620</td>\n",
       "      <td>-0.1476</td>\n",
       "      <td>0.2916</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>985.48</td>\n",
       "      <td>0.60231</td>\n",
       "      <td>-0.0540</td>\n",
       "      <td>-0.0864</td>\n",
       "      <td>0.2916</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>985.46</td>\n",
       "      <td>0.41579</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>-0.2412</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventActNumNoZero  FP34okNoZero  FP34ok_ff_LoadOnlyNoZero     aLx     aLy  \\\n",
       "0                  1        984.18                   1.06970  0.1944 -0.0576   \n",
       "1                  1        984.84                   0.92797 -0.0720  0.0756   \n",
       "2                  1        985.28                   0.77270 -0.1620 -0.1476   \n",
       "3                  1        985.48                   0.60231 -0.0540 -0.0864   \n",
       "4                  1        985.46                   0.41579  0.0540  0.0144   \n",
       "\n",
       "      aLz  aRx  aRy  aRz  \n",
       "0 -0.0684    0    0    0  \n",
       "1 -0.2808    0    0    0  \n",
       "2  0.2916    0    0    0  \n",
       "3  0.2916    0    0    0  \n",
       "4 -0.2412    0    0    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lift_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select_Data = Lift_Data['FP34okNoZero', 'FP34ok_ff_LoadOnlyNoZero', 'aLx', 'aRx']\n",
    "select_Data = Lift_Data[['FP34ok_ff_LoadOnlyNoZero', 'aLx','aLy','aLz', 'aRx','aRy','aRz']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x205ef386a20>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x205eba23eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2)\n",
    "time = Lift_Data.index.values\n",
    "listed_Event = Lift_Data['EventActNumNoZero']\n",
    "plt.plot(time, listed_Event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\pipeline.py:250: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\pipeline.py:250: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\pipeline.py:250: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\pipeline.py:250: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\pipeline.py:250: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\pipeline.py:250: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "# Run this for MultiClassification\n",
    "# Create empty lists to append to.\n",
    "names = []\n",
    "Event = []\n",
    "Chance = []\n",
    "Overlap = []\n",
    "Lengths = []\n",
    "Accuracy = []\n",
    "TestAcc = []\n",
    "Precision = []\n",
    "Recall = []\n",
    "Kappa = []\n",
    "\n",
    "# Create test conditions to go into the loop\n",
    "#test_Lengths = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "#overlaps = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "test_Lengths = [2.5]\n",
    "overlaps = [0.9]\n",
    "list_Events = ['Stand_Free', 'Lift_Squat', 'Lower_Squat']\n",
    "#algorithms = ['LDA', 'KNN', 'NB', 'QDA', 'LR', 'SVC']\n",
    "algorithms = ['KNN']\n",
    "#cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "cv = KFold(5)\n",
    "# Add stratified data split\n",
    "\n",
    "\n",
    "events_Array = initialize_Event_Array(test_Lengths, overlaps, list_Events, algorithms, 120)\n",
    "\n",
    "# Create numpy arrays \n",
    "total_Trial_Pred = np.array([])\n",
    "total_Trial_Test = np.array([])\n",
    "\n",
    "for my_Epoch_Length in test_Lengths:\n",
    "    for my_Overlap in overlaps:\n",
    "        \n",
    "\n",
    "        # Create dataset for machine learning\n",
    "        labels = sliding_Window_Events(events, my_Epoch_Length, my_Overlap, 120)\n",
    "        event = dummy_Events(labels)\n",
    "        chosen_Event = labels  # 1-Stand_Free, 3-Lift_Squat, 5-Lower_Squat\n",
    "        #chosen_Event = event[my_Event] # 1-Stand_Free, 3-Lift_Squat, 5-Lower_Squat\n",
    "        #current_Event = my_Event\n",
    "        #n = round(((number_Of_Samples - minL*sample_Rate)/(slide*sample_Rate)),0)-1\n",
    "        data_Frame = pd.DataFrame(sliding_Window(data, events, my_Epoch_Length, my_Overlap, 120))\n",
    "        data_Only = data_Frame[data_Frame.columns[2:]]\n",
    "        #data_Only = select_Data\n",
    "        \n",
    "        #pca = decomposition.PCA(n_components=0.95)\n",
    "\n",
    "        # Define the parameters\n",
    "        #svcParameters = [{'gamma': 10.0 ** np.arange(-5, 4), 'C': 10.0 ** np.arange(-2, 7)}]\n",
    "        #ldaParameters = [{'n_components' : [10, 20, 30, 40], 'solver': ['svd', 'lsqr', 'eigen']}]\n",
    "        ldaParameters = [{'n_components' : [3, 4, 5, 6], 'solver': ['svd', 'lsqr', 'eigen']}]\n",
    "        knnParameters = [{'n_neighbors' : [5, 10, 15, 20]}]\n",
    "        #knnParameters = [{'n_neighbors' : [50, 100, 150, 200]}]\n",
    "        \n",
    "        # Assemble default classifiers\n",
    "        #svc = SVC(probability=True)\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        knn = KNeighborsClassifier()\n",
    "        nb = GaussianNB()\n",
    "        qda = QuadraticDiscriminantAnalysis()\n",
    "        lr = LogisticRegression()\n",
    "\n",
    "        # Assemble grid parameter classifiers\n",
    "        #svc2 = GridSearchCV(SVC(probability=True), svcParameters, cv=cv, scoring='accuracy')\n",
    "        lda2 = GridSearchCV(LinearDiscriminantAnalysis(), ldaParameters, cv=cv, scoring='accuracy')\n",
    "        knn2 = GridSearchCV(KNeighborsClassifier(), knnParameters, cv=cv, scoring='accuracy')\n",
    "\n",
    "        # Split the test and train datasets\n",
    "        for train_idx, test_idx in cv.split(labels):\n",
    "            y_train, y_test = chosen_Event.loc[train_idx], chosen_Event.loc[test_idx]\n",
    "            X_train, X_test = data_Only.loc[train_idx,:], data_Only.loc[test_idx,:]\n",
    "            \n",
    "            \n",
    "            #total_Trial_Test.append(y_test)\n",
    "\n",
    "        # Perform the machine learning\n",
    "        currentName = algorithms\n",
    "        #classifier = [Pipeline([('LDA', lda)]), Pipeline([('KNN', knn)]), Pipeline([('NB', nb)]), Pipeline([('QDA', qda)]), Pipeline([('LR', lr)])]\n",
    "        classifier = [Pipeline([('KNN', knn)])]\n",
    "        #classifier = [Pipeline([('LDA', lda)])]\n",
    "        #classifier = [Pipeline([('LDA', lda)]), Pipeline([('KNN', knn)])]\n",
    "        count = 0\n",
    "        for my_Classifier in classifier:\n",
    "            sAccuracy = cross_val_score(my_Classifier, X_train, y_train, scoring = 'accuracy', cv=cv, n_jobs=1)\n",
    "\n",
    "            # Printing the results\n",
    "            labels = chosen_Event\n",
    "            #class_balance = np.mean(labels == labels[0])\n",
    "            #class_balance = np.mean(labels)\n",
    "            #class_balance = max(class_balance, 1. - class_balance)\n",
    "            y_pred = my_Classifier.fit(X_train, y_train).predict(X_test)\n",
    "            y_pred_prob = my_Classifier.predict_proba(X_test)\n",
    "            #y_pred_class = binarize(y_pred_prob, 0.5)[:,0] # Predict events labeled as 1 not 2 which in this case is zero.\n",
    "\n",
    "            #rocTest = (1-y_test)+1\n",
    "            #auc = roc_auc_score(rocTest, y_pred_class)\n",
    "            tacc = accuracy_score(y_test, y_pred)\n",
    "            #prec = precision_score(y_test, y_pred)\n",
    "            #recall = recall_score(y_test, y_pred)\n",
    "            #kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "            names.append(currentName[count])\n",
    "            #Event.append(current_Event)\n",
    "            Lengths.append(my_Epoch_Length)\n",
    "            #Chance.append(class_balance)\n",
    "            Overlap.append(my_Overlap)\n",
    "            Accuracy.append(np.mean(sAccuracy))\n",
    "            TestAcc.append(tacc)\n",
    "            #Precision.append(prec)\n",
    "            #Recall.append(recall)\n",
    "            #AUC.append(auc)\n",
    "            #Kappa.append(kappa)\n",
    "            count = count + 1\n",
    "\n",
    "            #header_Name = [my_Event, list(my_Classifier.named_steps.keys())[0], str(my_Epoch_Length), str(my_Overlap)]\n",
    "            #current_Column = '_'.join(header_Name)\n",
    "\n",
    "        # Create a data frame that appends new columns\n",
    "        # Reprint the events\n",
    "        \n",
    "        \n",
    "        #true_Events = y_test\n",
    "        #current_Prediction = y_pred\n",
    "        \n",
    "            \n",
    "\n",
    "# #myData = {'Name' : names, 'Event': Event, 'Epochs' : Lengths, 'Chance' : Chance, 'Accuracy' : Accuracy, 'TestAcc' : TestAcc, 'Precision': Precision, 'Recall': Recall, 'AUC' : AUC, 'Kappa': Kappa}\n",
    "# myData = {'Name' : names, 'Epochs' : Lengths, 'Overlap' : Overlap,  'Accuracy' : Accuracy, 'TestAcc' : TestAcc, 'Precision': Precision, 'Recall': Recall,  'Kappa': Kappa}\n",
    "\n",
    "# test5 = pd.DataFrame(myData, columns = ['Name', 'Epochs', 'Overlap', 'Accuracy', 'TestAcc', 'Precision', 'Recall', 'Kappa'])\n",
    "# #test5.to_csv('testing.csv')\n",
    "\n",
    "myData = {'Name' : names, 'Epochs' : Lengths, 'Overlap' : Overlap,  'Accuracy' : Accuracy, 'TestAcc' : TestAcc}\n",
    "\n",
    "test5 = pd.DataFrame(myData, columns = ['Name', 'Epochs', 'Overlap', 'Accuracy', 'TestAcc'])\n",
    "#test5.to_csv('revised_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Overlap</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TestAcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.725303</td>\n",
       "      <td>0.895522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name  Epochs  Overlap  Accuracy   TestAcc\n",
       "0  KNN     2.5      0.9  0.725303  0.895522"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1074,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51396648, 0.5698324 , 0.54748603, 0.56741573, 0.7247191 ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sAccuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this for MultiClassification\n",
    "# Create empty lists to append to.\n",
    "names = []\n",
    "Event = []\n",
    "Chance = []\n",
    "Overlap = []\n",
    "Lengths = []\n",
    "Accuracy = []\n",
    "TestAcc = []\n",
    "Precision = []\n",
    "Recall = []\n",
    "Kappa = []\n",
    "\n",
    "# Create test conditions to go into the loop\n",
    "test_Lengths = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "#overlaps = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "#test_Lengths = [2.5]\n",
    "overlaps = [0.9]\n",
    "list_Events = ['Stand_Free', 'Lift_Squat', 'Lower_Squat']\n",
    "algorithms = ['LDA', 'KNN', 'NB', 'QDA', 'LR', 'SVC']\n",
    "#algorithms = ['KNN']\n",
    "#cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "cv = KFold(5)\n",
    "# Add stratified data split\n",
    "\n",
    "\n",
    "events_Array = initialize_Event_Array(test_Lengths, overlaps, list_Events, algorithms, 120)\n",
    "\n",
    "for my_Epoch_Length in test_Lengths:\n",
    "    for my_Overlap in overlaps:\n",
    "\n",
    "        # Create dataset for machine learning\n",
    "        labels = sliding_Window_Events(events, my_Epoch_Length, my_Overlap, 120)\n",
    "        event = dummy_Events(labels)\n",
    "        chosen_Event = labels  # 1-Stand_Free, 3-Lift_Squat, 5-Lower_Squat\n",
    "        #chosen_Event = event[my_Event] # 1-Stand_Free, 3-Lift_Squat, 5-Lower_Squat\n",
    "        #current_Event = my_Event\n",
    "        #n = round(((number_Of_Samples - minL*sample_Rate)/(slide*sample_Rate)),0)-1\n",
    "        data_Frame = pd.DataFrame(sliding_Window(data, events, my_Epoch_Length, my_Overlap, 120))\n",
    "        data_Only = data_Frame[data_Frame.columns[2:]]\n",
    "        #data_Only = select_Data\n",
    "        \n",
    "        #pca = decomposition.PCA(n_components=0.95)\n",
    "\n",
    "        # Define the parameters\n",
    "        #svcParameters = [{'gamma': 10.0 ** np.arange(-5, 4), 'C': 10.0 ** np.arange(-2, 7)}]\n",
    "        #ldaParameters = [{'n_components' : [10, 20, 30, 40], 'solver': ['svd', 'lsqr', 'eigen']}]\n",
    "        ldaParameters = [{'n_components' : [3, 4, 5, 6], 'solver': ['svd', 'lsqr', 'eigen']}]\n",
    "        #knnParameters = [{'n_neighbors' : [5, 10, 15, 20]}]\n",
    "        knnParameters = [{'n_neighbors' : [50, 100, 150, 200]}]\n",
    "        \n",
    "        # Assemble default classifiers\n",
    "        #svc = SVC(probability=True)\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        knn = KNeighborsClassifier()\n",
    "        nb = GaussianNB()\n",
    "        qda = QuadraticDiscriminantAnalysis()\n",
    "        lr = LogisticRegression()\n",
    "\n",
    "        # Assemble grid parameter classifiers\n",
    "        #svc2 = GridSearchCV(SVC(probability=True), svcParameters, cv=cv, scoring='accuracy')\n",
    "        lda2 = GridSearchCV(LinearDiscriminantAnalysis(), ldaParameters, cv=cv, scoring='accuracy')\n",
    "        knn2 = GridSearchCV(KNeighborsClassifier(), knnParameters, cv=cv, scoring='accuracy')\n",
    "\n",
    "        # Split the test and train datasets\n",
    "        for train_idx, test_idx in cv.split(labels):\n",
    "            y_train, y_test = chosen_Event.loc[train_idx], chosen_Event.loc[test_idx]\n",
    "            X_train, X_test = data_Only.loc[train_idx,:], data_Only.loc[test_idx,:]\n",
    "\n",
    "        # Perform the machine learning\n",
    "        currentName = algorithms\n",
    "        classifier = [Pipeline([('LDA', lda)]), Pipeline([('KNN', knn)]), Pipeline([('NB', nb)]), Pipeline([('QDA', qda)]), Pipeline([('LR', lr)])]\n",
    "        #classifier = [Pipeline([('KNN', knn)])]\n",
    "        #classifier = [Pipeline([('LDA', lda)])]\n",
    "        count = 0\n",
    "        for my_Classifier in classifier:\n",
    "            sAccuracy = cross_val_score(my_Classifier, X_train, y_train, scoring = 'accuracy', cv=cv, n_jobs=1)\n",
    "\n",
    "            # Printing the results\n",
    "            labels = chosen_Event\n",
    "            #class_balance = np.mean(labels == labels[0])\n",
    "            #class_balance = np.mean(labels)\n",
    "            #class_balance = max(class_balance, 1. - class_balance)\n",
    "            y_pred = my_Classifier.fit(X_train, y_train).predict(X_test)\n",
    "            y_pred_prob = my_Classifier.predict_proba(X_test)\n",
    "            #y_pred_class = binarize(y_pred_prob, 0.5)[:,0] # Predict events labeled as 1 not 2 which in this case is zero.\n",
    "\n",
    "            #rocTest = (1-y_test)+1\n",
    "            #auc = roc_auc_score(rocTest, y_pred_class)\n",
    "            tacc = accuracy_score(y_test, y_pred)\n",
    "            #prec = precision_score(y_test, y_pred)\n",
    "            #recall = recall_score(y_test, y_pred)\n",
    "            #kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "            names.append(currentName[count])\n",
    "            #Event.append(current_Event)\n",
    "            Lengths.append(my_Epoch_Length)\n",
    "            #Chance.append(class_balance)\n",
    "            Overlap.append(my_Overlap)\n",
    "            Accuracy.append(np.mean(sAccuracy))\n",
    "            TestAcc.append(tacc)\n",
    "            #Precision.append(prec)\n",
    "            #Recall.append(recall)\n",
    "            #AUC.append(auc)\n",
    "            #Kappa.append(kappa)\n",
    "            count = count + 1\n",
    "\n",
    "            #header_Name = [my_Event, list(my_Classifier.named_steps.keys())[0], str(my_Epoch_Length), str(my_Overlap)]\n",
    "            #current_Column = '_'.join(header_Name)\n",
    "\n",
    "        # Create a data frame that appends new columns\n",
    "        # Reprint the events\n",
    "        true_Events = y_test\n",
    "        current_Prediction = y_pred\n",
    "        \n",
    "            \n",
    "\n",
    "# #myData = {'Name' : names, 'Event': Event, 'Epochs' : Lengths, 'Chance' : Chance, 'Accuracy' : Accuracy, 'TestAcc' : TestAcc, 'Precision': Precision, 'Recall': Recall, 'AUC' : AUC, 'Kappa': Kappa}\n",
    "# myData = {'Name' : names, 'Epochs' : Lengths, 'Overlap' : Overlap,  'Accuracy' : Accuracy, 'TestAcc' : TestAcc, 'Precision': Precision, 'Recall': Recall,  'Kappa': Kappa}\n",
    "\n",
    "# test5 = pd.DataFrame(myData, columns = ['Name', 'Epochs', 'Overlap', 'Accuracy', 'TestAcc', 'Precision', 'Recall', 'Kappa'])\n",
    "# #test5.to_csv('testing.csv')\n",
    "\n",
    "myData = {'Name' : names, 'Epochs' : Lengths, 'Overlap' : Overlap,  'Accuracy' : Accuracy, 'TestAcc' : TestAcc}\n",
    "\n",
    "test5 = pd.DataFrame(myData, columns = ['Name', 'Epochs', 'Overlap', 'Accuracy', 'TestAcc'])\n",
    "test5.to_csv('revised_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2sec = {'TrueEvents': y_test, 'PredictedEvents': current_Prediction}\n",
    "result_DF = pd.DataFrame(knn2sec, columns = ['TrueEvents', 'PredictedEvents'])\n",
    "result_DF.to_csv('knn2sec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1efb9a61ba8>]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(6)\n",
    "time = y_test.index.values\n",
    "plt.plot(time, y_test, 'b')\n",
    "plt.plot(time, y_pred, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[221   9  25]\n",
      " [  4  34   9]\n",
      " [  3   4  27]]\n",
      "Normalized confusion matrix\n",
      "[[0.87 0.04 0.1 ]\n",
      " [0.09 0.72 0.19]\n",
      " [0.09 0.12 0.79]]\n"
     ]
    }
   ],
   "source": [
    "# Find the best setting\n",
    "# Create a confusion matrix from the best setting\n",
    "#class_names = ['Stand_Free', 'Lift_Squat', 'Lower_Squat']\n",
    "class_names = ['Stand_Free', 'Lower_Squat', 'Lift_Squat']\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Events\n",
       "1344       1\n",
       "1345       1\n",
       "1346       1\n",
       "1347       1\n",
       "1348       1\n",
       "1349       1\n",
       "1350       1\n",
       "1351       1\n",
       "1352       1\n",
       "1353       1\n",
       "1354       1\n",
       "1355       1\n",
       "1356       1\n",
       "1357       1\n",
       "1358       1\n",
       "1359       1\n",
       "1360       1\n",
       "1361       1\n",
       "1362       1\n",
       "1363       1\n",
       "1364       1\n",
       "1365       1\n",
       "1366       1\n",
       "1367       1\n",
       "1368       1\n",
       "1369       3\n",
       "1370       3\n",
       "1371       3\n",
       "1372       3\n",
       "1373       3\n",
       "...      ...\n",
       "1650       1\n",
       "1651       1\n",
       "1652       1\n",
       "1653       1\n",
       "1654       1\n",
       "1655       1\n",
       "1656       1\n",
       "1657       1\n",
       "1658       1\n",
       "1659       3\n",
       "1660       3\n",
       "1661       3\n",
       "1662       3\n",
       "1663       3\n",
       "1664       3\n",
       "1665       3\n",
       "1666       3\n",
       "1667       3\n",
       "1668       3\n",
       "1669       1\n",
       "1670       1\n",
       "1671       1\n",
       "1672       1\n",
       "1673       1\n",
       "1674       1\n",
       "1675       1\n",
       "1676       1\n",
       "1677       1\n",
       "1678       1\n",
       "1679       1\n",
       "\n",
       "[336 rows x 1 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lower_Squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lower_Squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lower_Squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stand_Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stand_Free</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Events\n",
       "0  Lower_Squat\n",
       "1  Lower_Squat\n",
       "2  Lower_Squat\n",
       "3   Stand_Free\n",
       "4   Stand_Free"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-Stand_Free, 3-Lift_Squat, 5-Lower_Squat\n",
    "rename = labels\n",
    "rename[rename == 1] = 'Stand_Free'\n",
    "rename[rename == 3] = 'Lift_Squat'\n",
    "rename[rename == 5] = 'Lower_Squat'\n",
    "rename.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this preliminary data, I will focus on the variables that can be obtained from the wearable sensors. These variables include LoadOnly, aCOM_TNH_x, aCOM_TNH_y, aCOM_TNH_z, aLHAND_x, aLHAND_y, aLHAND_z, aLANK_x, aLANK_y and aLANK_z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to append to.\n",
    "names = []\n",
    "Event = []\n",
    "Chance = []\n",
    "Overlap = []\n",
    "Lengths = []\n",
    "Accuracy = []\n",
    "TestAcc = []\n",
    "Precision = []\n",
    "Recall = []\n",
    "Kappa = []\n",
    "\n",
    "# Create test conditions to go into the loop\n",
    "#test_Lengths = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "#overlaps = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "test_Lengths = [2.0]\n",
    "overlaps = [0.5, 0.9]\n",
    "list_Events = ['Stand_Free', 'Lift_Squat', 'Lower_Squat']\n",
    "algorithms = ['LDA', 'KNN', 'NB', 'QDA', 'LR']\n",
    "cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add stratified data split\n",
    "\n",
    "\n",
    "events_Array = initialize_Event_Array(test_Lengths, overlaps, list_Events, algorithms, 120)\n",
    "\n",
    "for my_Event in list_Events:\n",
    "    for my_Epoch_Length in test_Lengths:\n",
    "        for my_Overlap in overlaps:\n",
    "\n",
    "            # Create dataset for machine learning\n",
    "            labels = sliding_Window_Events(events, my_Epoch_Length, my_Overlap, 120)\n",
    "            event = dummy_Events(labels)\n",
    "            chosen_Event = event[my_Event] # 1-Stand_Free, 3-Lift_Squat, 5-Lower_Squat\n",
    "            current_Event = my_Event\n",
    "            #n = round(((number_Of_Samples - minL*sample_Rate)/(slide*sample_Rate)),0)-1\n",
    "            data_Frame = pd.DataFrame(sliding_Window(data, events, my_Epoch_Length, my_Overlap, 120))\n",
    "            data_Only = data_Frame[data_Frame.columns[2:]]\n",
    "\n",
    "            # Define the parameters\n",
    "            svcParameters = [{'gamma': 10.0 ** np.arange(-5, 4), 'C': 10.0 ** np.arange(-2, 7)}]\n",
    "            ldaParameters = [{'n_components' : [10, 20, 30, 40], 'solver': ['svd', 'lsqr', 'eigen']}]\n",
    "            knnParameters = [{'n_neighbors' : [5, 10, 15, 20]}]\n",
    "            #artParameters = [{'max_features' : [2, 4, 6, 8, 10]}]\n",
    "            #fParameters = [{'max_features': [\"sqrt\", \"log2\", None, 1], 'max_depth':[None, 15, 30, 50], 'min_samples_leaf': [2, 5, 10]}]\n",
    "\n",
    "            # Assemble default classifiers\n",
    "            svc = SVC(probability=True)\n",
    "            lda = LinearDiscriminantAnalysis()\n",
    "            knn = KNeighborsClassifier()\n",
    "            #cart = DecisionTreeClassifier()\n",
    "            nb = GaussianNB()\n",
    "            qda = QuadraticDiscriminantAnalysis()\n",
    "            lr = LogisticRegression()\n",
    "            #rf = RandomForestClassifier()\n",
    "\n",
    "            # Assemble grid parameter classifiers\n",
    "            svc2 = GridSearchCV(SVC(probability=True), svcParameters, cv=cv, scoring='accuracy')\n",
    "            lda2 = GridSearchCV(LinearDiscriminantAnalysis(), ldaParameters, cv=cv, scoring='accuracy')\n",
    "            knn2 = GridSearchCV(KNeighborsClassifier(), knnParameters, cv=cv, scoring='accuracy')\n",
    "            #cart2 = GridSearchCV(DecisionTreeClassifier(), cartParameters, cv=cv, scoring='accuracy')\n",
    "            #nb2 = GridSearchCV(GaussianNB(), nbParameters, cv=cv, scoring='accuracy')\n",
    "            #qda2 = GridSearchCV(QuadraticDiscriminantAnalysis(), qdaParameters, cv=cv, scoring='accuracy')\n",
    "            #rf2 = GridSearchCV(RandomForestClassifier(), rfParameters, cv=cv, scoring='accuracy')\n",
    "            \n",
    "            # Split the test and train datasets\n",
    "            for train_idx, test_idx in cv.split(labels):\n",
    "                y_train, y_test = chosen_Event.loc[train_idx], chosen_Event.loc[test_idx]\n",
    "                X_train, X_test = data_Only.loc[train_idx,:], data_Only.loc[test_idx,:]\n",
    "                \n",
    "            # Perform the machine learning\n",
    "            currentName = algorithms\n",
    "            #currentName = ['LDA']\n",
    "            #classifier = [ Pipeline([('KNN', knn2)]), Pipeline([('QDA', qda)]), Pipeline([('LR', lr)])]\n",
    "            classifier = [Pipeline([('LDA', lda)]), Pipeline([('KNN', knn)]), Pipeline([('NB', nb)]), Pipeline([('QDA', qda)]), Pipeline([('LR', lr)])]\n",
    "            #classifier = [Pipeline([('LDA', lda)])]\n",
    "            count = 0\n",
    "            for my_Classifier in classifier:\n",
    "                sAccuracy = cross_val_score(my_Classifier, X_train, y_train, scoring = 'accuracy', cv=cv, n_jobs=1)\n",
    "\n",
    "                # Printing the results\n",
    "                labels = chosen_Event\n",
    "                class_balance = np.mean(labels == labels[0])\n",
    "                class_balance = np.mean(labels)\n",
    "                class_balance = max(class_balance, 1. - class_balance)\n",
    "                y_pred = my_Classifier.fit(X_train, y_train).predict(X_test)\n",
    "                y_pred_prob = my_Classifier.predict_proba(X_test)\n",
    "                #y_pred_class = binarize(y_pred_prob, 0.5)[:,0] # Predict events labeled as 1 not 2 which in this case is zero.\n",
    "\n",
    "                rocTest = (1-y_test)+1\n",
    "                #auc = roc_auc_score(rocTest, y_pred_class)\n",
    "                tacc = accuracy_score(y_test, y_pred)\n",
    "                prec = precision_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "                kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "                names.append(currentName[count])\n",
    "                Event.append(current_Event)\n",
    "                Lengths.append(my_Epoch_Length)\n",
    "                Chance.append(class_balance)\n",
    "                Overlap.append(my_Overlap)\n",
    "                Accuracy.append(np.mean(sAccuracy))\n",
    "                TestAcc.append(tacc)\n",
    "                Precision.append(prec)\n",
    "                Recall.append(recall)\n",
    "                #AUC.append(auc)\n",
    "                Kappa.append(kappa)\n",
    "                count = count + 1\n",
    "                \n",
    "                header_Name = [my_Event, list(my_Classifier.named_steps.keys())[0], str(my_Epoch_Length), str(my_Overlap)]\n",
    "                current_Column = '_'.join(header_Name)\n",
    "                \n",
    "                \n",
    "                # Fix This\n",
    "                #events_Array['tested_Column'][[test_idx]] = 1\n",
    "                #events_Array[current_Column][[test_idx]] = y_pred\n",
    "                \n",
    "            # Create a data frame that appends new columns\n",
    "            # Reprint the events\n",
    "            #true_Events = y_test\n",
    "            \n",
    "\n",
    "#myData = {'Name' : names, 'Event': Event, 'Epochs' : Lengths, 'Chance' : Chance, 'Accuracy' : Accuracy, 'TestAcc' : TestAcc, 'Precision': Precision, 'Recall': Recall, 'AUC' : AUC, 'Kappa': Kappa}\n",
    "myData = {'Name' : names, 'Event': Event, 'Epochs' : Lengths, 'Overlap' : Overlap,  'Accuracy' : Accuracy, 'TestAcc' : TestAcc, 'Precision': Precision, 'Recall': Recall,  'Kappa': Kappa}\n",
    "\n",
    "test5 = pd.DataFrame(myData, columns = ['Name', 'Event', 'Epochs', 'Overlap', 'Accuracy', 'TestAcc', 'Precision', 'Recall', 'Kappa'])\n",
    "#test5.to_csv('testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to append to.\n",
    "names = []\n",
    "Event = []\n",
    "Chance = []\n",
    "Overlap = []\n",
    "Lengths = []\n",
    "Accuracy = []\n",
    "TestAcc = []\n",
    "Precision = []\n",
    "Recall = []\n",
    "Kappa = []\n",
    "\n",
    "# Create test conditions to go into the loop\n",
    "#test_Lengths = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "#overlaps = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "test_Lengths = [2.0]\n",
    "overlaps = [0.5, 0.9]\n",
    "list_Events = ['Stand_Free', 'Lift_Squat', 'Lower_Squat']\n",
    "algorithms = ['LDA', 'KNN', 'NB', 'LR']\n",
    "#cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "cv = KFold(5)\n",
    "# Add stratified data split\n",
    "\n",
    "\n",
    "events_Array = initialize_Event_Array(test_Lengths, overlaps, list_Events, algorithms, 120)\n",
    "\n",
    "for my_Event in list_Events:\n",
    "    for my_Epoch_Length in test_Lengths:\n",
    "        for my_Overlap in overlaps:\n",
    "\n",
    "            # Create dataset for machine learning\n",
    "            labels = sliding_Window_Events(events, my_Epoch_Length, my_Overlap, 120)\n",
    "            event = dummy_Events(labels)\n",
    "            chosen_Event = event[my_Event] # 1-Stand_Free, 3-Lift_Squat, 5-Lower_Squat\n",
    "            current_Event = my_Event\n",
    "            #n = round(((number_Of_Samples - minL*sample_Rate)/(slide*sample_Rate)),0)-1\n",
    "            data_Frame = pd.DataFrame(sliding_Window(data, events, my_Epoch_Length, my_Overlap, 120))\n",
    "            data_Only = data_Frame[data_Frame.columns[2:]]\n",
    "\n",
    "            # Define the parameters\n",
    "            svcParameters = [{'gamma': 10.0 ** np.arange(-5, 4), 'C': 10.0 ** np.arange(-2, 7)}]\n",
    "            ldaParameters = [{'n_components' : [10, 20, 30, 40], 'solver': ['svd', 'lsqr', 'eigen']}]\n",
    "            knnParameters = [{'n_neighbors' : [5, 10, 15, 20]}]\n",
    "            #artParameters = [{'max_features' : [2, 4, 6, 8, 10]}]\n",
    "            #fParameters = [{'max_features': [\"sqrt\", \"log2\", None, 1], 'max_depth':[None, 15, 30, 50], 'min_samples_leaf': [2, 5, 10]}]\n",
    "\n",
    "            # Assemble default classifiers\n",
    "            svc = SVC(probability=True)\n",
    "            lda = LinearDiscriminantAnalysis()\n",
    "            knn = KNeighborsClassifier()\n",
    "            #cart = DecisionTreeClassifier()\n",
    "            nb = GaussianNB()\n",
    "            qda = QuadraticDiscriminantAnalysis()\n",
    "            lr = LogisticRegression()\n",
    "            #rf = RandomForestClassifier()\n",
    "\n",
    "            # Assemble grid parameter classifiers\n",
    "            svc2 = GridSearchCV(SVC(probability=True), svcParameters, cv=cv, scoring='accuracy')\n",
    "            lda2 = GridSearchCV(LinearDiscriminantAnalysis(), ldaParameters, cv=cv, scoring='accuracy')\n",
    "            knn2 = GridSearchCV(KNeighborsClassifier(), knnParameters, cv=cv, scoring='accuracy')\n",
    "            #cart2 = GridSearchCV(DecisionTreeClassifier(), cartParameters, cv=cv, scoring='accuracy')\n",
    "            #nb2 = GridSearchCV(GaussianNB(), nbParameters, cv=cv, scoring='accuracy')\n",
    "            #qda2 = GridSearchCV(QuadraticDiscriminantAnalysis(), qdaParameters, cv=cv, scoring='accuracy')\n",
    "            #rf2 = GridSearchCV(RandomForestClassifier(), rfParameters, cv=cv, scoring='accuracy')\n",
    "            \n",
    "            # Split the test and train datasets\n",
    "            for train_idx, test_idx in cv.split(labels):\n",
    "                y_train, y_test = chosen_Event.loc[train_idx], chosen_Event.loc[test_idx]\n",
    "                X_train, X_test = data_Only.loc[train_idx,:], data_Only.loc[test_idx,:]\n",
    "                \n",
    "            # Perform the machine learning\n",
    "            currentName = algorithms\n",
    "            #currentName = ['LDA']\n",
    "            #classifier = [ Pipeline([('KNN', knn2)]), Pipeline([('QDA', qda)]), Pipeline([('LR', lr)])]\n",
    "            classifier = [Pipeline([('LDA', lda)]), Pipeline([('KNN', knn)]), Pipeline([('NB', nb)]), Pipeline([('QDA', qda)]), Pipeline([('LR', lr)])]\n",
    "            #classifier = [Pipeline([('LDA', lda)])]\n",
    "            count = 0\n",
    "            for my_Classifier in classifier:\n",
    "                sAccuracy = cross_val_score(my_Classifier, X_train, y_train, scoring = 'accuracy', cv=cv, n_jobs=1)\n",
    "\n",
    "                # Printing the results\n",
    "                labels = chosen_Event\n",
    "                class_balance = np.mean(labels == labels[0])\n",
    "                class_balance = np.mean(labels)\n",
    "                class_balance = max(class_balance, 1. - class_balance)\n",
    "                y_pred = my_Classifier.fit(X_train, y_train).predict(X_test)\n",
    "                y_pred_prob = my_Classifier.predict_proba(X_test)\n",
    "                #y_pred_class = binarize(y_pred_prob, 0.5)[:,0] # Predict events labeled as 1 not 2 which in this case is zero.\n",
    "\n",
    "                rocTest = (1-y_test)+1\n",
    "                #auc = roc_auc_score(rocTest, y_pred_class)\n",
    "                tacc = accuracy_score(y_test, y_pred)\n",
    "                prec = precision_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "                kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "                names.append(currentName[count])\n",
    "                Event.append(current_Event)\n",
    "                Lengths.append(my_Epoch_Length)\n",
    "                Chance.append(class_balance)\n",
    "                Overlap.append(my_Overlap)\n",
    "                Accuracy.append(np.mean(sAccuracy))\n",
    "                TestAcc.append(tacc)\n",
    "                Precision.append(prec)\n",
    "                Recall.append(recall)\n",
    "                #AUC.append(auc)\n",
    "                Kappa.append(kappa)\n",
    "                count = count + 1\n",
    "                \n",
    "                header_Name = [my_Event, list(my_Classifier.named_steps.keys())[0], str(my_Epoch_Length), str(my_Overlap)]\n",
    "                current_Column = '_'.join(header_Name)\n",
    "\n",
    "            # Create a data frame that appends new columns\n",
    "            # Reprint the events\n",
    "            true_Events = y_test\n",
    "            \n",
    "\n",
    "#myData = {'Name' : names, 'Event': Event, 'Epochs' : Lengths, 'Chance' : Chance, 'Accuracy' : Accuracy, 'TestAcc' : TestAcc, 'Precision': Precision, 'Recall': Recall, 'AUC' : AUC, 'Kappa': Kappa}\n",
    "myData = {'Name' : names, 'Event': Event, 'Epochs' : Lengths, 'Overlap' : Overlap,  'Accuracy' : Accuracy, 'TestAcc' : TestAcc, 'Precision': Precision, 'Recall': Recall,  'Kappa': Kappa}\n",
    "\n",
    "test5 = pd.DataFrame(myData, columns = ['Name', 'Event', 'Epochs', 'Overlap', 'Accuracy', 'TestAcc', 'Precision', 'Recall', 'Kappa'])\n",
    "#test5.to_csv('testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Event</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Overlap</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TestAcc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Stand_Free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.914186</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.696145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Stand_Free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.876799</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.704846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB</td>\n",
       "      <td>Stand_Free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.794689</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.606345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QDA</td>\n",
       "      <td>Stand_Free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.398882</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>Stand_Free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.891754</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.738719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Stand_Free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.907726</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.927126</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.653787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Stand_Free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.893578</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.968326</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.658493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>Stand_Free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.761960</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.571611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QDA</td>\n",
       "      <td>Stand_Free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.406153</td>\n",
       "      <td>0.241071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR</td>\n",
       "      <td>Stand_Free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.893625</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.945607</td>\n",
       "      <td>0.886275</td>\n",
       "      <td>0.679956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Lift_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.828302</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.177914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Lift_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.813487</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.647986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NB</td>\n",
       "      <td>Lift_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.757372</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.413016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>QDA</td>\n",
       "      <td>Lift_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.798672</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LR</td>\n",
       "      <td>Lift_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.832075</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.367925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Lift_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.836337</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.307713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Lift_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.838554</td>\n",
       "      <td>0.922619</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.666539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NB</td>\n",
       "      <td>Lift_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.722535</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.327261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QDA</td>\n",
       "      <td>Lift_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.794696</td>\n",
       "      <td>0.860119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LR</td>\n",
       "      <td>Lift_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.827398</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.503461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Lower_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.828302</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.203111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Lower_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.825087</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.743295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NB</td>\n",
       "      <td>Lower_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.768903</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-0.010050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>QDA</td>\n",
       "      <td>Lower_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.802446</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LR</td>\n",
       "      <td>Lower_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.802376</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Lower_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.802816</td>\n",
       "      <td>0.836310</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.111709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Lower_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.826616</td>\n",
       "      <td>0.877976</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.503961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NB</td>\n",
       "      <td>Lower_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.765661</td>\n",
       "      <td>0.818452</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.063083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>QDA</td>\n",
       "      <td>Lower_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.799151</td>\n",
       "      <td>0.898810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LR</td>\n",
       "      <td>Lower_Squat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.802835</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.235410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name        Event  Epochs  Overlap  Accuracy   TestAcc  Precision  \\\n",
       "0   LDA   Stand_Free     2.0      0.5  0.914186  0.880597   0.918367   \n",
       "1   KNN   Stand_Free     2.0      0.5  0.876799  0.865672   1.000000   \n",
       "2    NB   Stand_Free     2.0      0.5  0.794689  0.850746   0.882353   \n",
       "3   QDA   Stand_Free     2.0      0.5  0.398882  0.268657   0.000000   \n",
       "4    LR   Stand_Free     2.0      0.5  0.891754  0.895522   0.937500   \n",
       "5   LDA   Stand_Free     2.0      0.9  0.907726  0.869048   0.927126   \n",
       "6   KNN   Stand_Free     2.0      0.9  0.893578  0.857143   0.968326   \n",
       "7    NB   Stand_Free     2.0      0.9  0.761960  0.839286   0.903614   \n",
       "8   QDA   Stand_Free     2.0      0.9  0.406153  0.241071   0.000000   \n",
       "9    LR   Stand_Free     2.0      0.9  0.893625  0.875000   0.945607   \n",
       "10  LDA   Lift_Squat     2.0      0.5  0.828302  0.880597   1.000000   \n",
       "11  KNN   Lift_Squat     2.0      0.5  0.813487  0.910448   0.636364   \n",
       "12   NB   Lift_Squat     2.0      0.5  0.757372  0.895522   0.750000   \n",
       "13  QDA   Lift_Squat     2.0      0.5  0.798672  0.865672   0.000000   \n",
       "14   LR   Lift_Squat     2.0      0.5  0.832075  0.880597   0.600000   \n",
       "15  LDA   Lift_Squat     2.0      0.9  0.836337  0.863095   0.518519   \n",
       "16  KNN   Lift_Squat     2.0      0.9  0.838554  0.922619   0.744186   \n",
       "17   NB   Lift_Squat     2.0      0.9  0.722535  0.848214   0.450000   \n",
       "18  QDA   Lift_Squat     2.0      0.9  0.794696  0.860119   0.000000   \n",
       "19   LR   Lift_Squat     2.0      0.9  0.827398  0.886905   0.609756   \n",
       "20  LDA  Lower_Squat     2.0      0.5  0.828302  0.805970   0.300000   \n",
       "21  KNN  Lower_Squat     2.0      0.5  0.825087  0.940299   0.777778   \n",
       "22   NB  Lower_Squat     2.0      0.5  0.768903  0.776119   0.125000   \n",
       "23  QDA  Lower_Squat     2.0      0.5  0.802446  0.865672   0.000000   \n",
       "24   LR  Lower_Squat     2.0      0.5  0.802376  0.820896   0.333333   \n",
       "25  LDA  Lower_Squat     2.0      0.9  0.802816  0.836310   0.200000   \n",
       "26  KNN  Lower_Squat     2.0      0.9  0.826616  0.877976   0.442623   \n",
       "27   NB  Lower_Squat     2.0      0.9  0.765661  0.818452   0.153846   \n",
       "28  QDA  Lower_Squat     2.0      0.9  0.799151  0.898810   0.000000   \n",
       "29   LR  Lower_Squat     2.0      0.9  0.802835  0.848214   0.292683   \n",
       "\n",
       "      Recall     Kappa  \n",
       "0   0.918367  0.696145  \n",
       "1   0.816327  0.704846  \n",
       "2   0.918367  0.606345  \n",
       "3   0.000000  0.000000  \n",
       "4   0.918367  0.738719  \n",
       "5   0.898039  0.653787  \n",
       "6   0.839216  0.658493  \n",
       "7   0.882353  0.571611  \n",
       "8   0.000000  0.000000  \n",
       "9   0.886275  0.679956  \n",
       "10  0.111111  0.177914  \n",
       "11  0.777778  0.647986  \n",
       "12  0.333333  0.413016  \n",
       "13  0.000000  0.000000  \n",
       "14  0.333333  0.367925  \n",
       "15  0.297872  0.307713  \n",
       "16  0.680851  0.666539  \n",
       "17  0.382979  0.327261  \n",
       "18  0.000000  0.000000  \n",
       "19  0.531915  0.503461  \n",
       "20  0.333333  0.203111  \n",
       "21  0.777778  0.743295  \n",
       "22  0.111111 -0.010050  \n",
       "23  0.000000  0.000000  \n",
       "24  0.333333  0.229885  \n",
       "25  0.205882  0.111709  \n",
       "26  0.794118  0.503961  \n",
       "27  0.176471  0.063083  \n",
       "28  0.000000  0.000000  \n",
       "29  0.352941  0.235410  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1efb0bb2f60>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_Time = chosen_Event.index.values\n",
    "test_Events = chosen_Event\n",
    "plt.plot(event_Time, test_Events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chosen_Event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1efaea8b390>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1efa9568198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = y_test.index.values\n",
    "plt.plot(time, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1efaf0039e8>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = y_train.index.values\n",
    "plt.plot(time, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this for MultiClassification\n",
    "# Create empty lists to append to.\n",
    "names = []\n",
    "Event = []\n",
    "Chance = []\n",
    "Overlap = []\n",
    "Lengths = []\n",
    "Accuracy = []\n",
    "TestAcc = []\n",
    "Precision = []\n",
    "Recall = []\n",
    "Kappa = []\n",
    "\n",
    "# Create test conditions to go into the loop\n",
    "#test_Lengths = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "#overlaps = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "test_Lengths = [2.0]\n",
    "overlaps = [0.5, 0.9]\n",
    "list_Events = ['Stand_Free', 'Lift_Squat', 'Lower_Squat']\n",
    "algorithms = ['LDA', 'KNN', 'NB', 'LR']\n",
    "#cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "cv = KFold(5)\n",
    "# Add stratified data split\n",
    "\n",
    "\n",
    "events_Array = initialize_Event_Array(test_Lengths, overlaps, list_Events, algorithms, 120)\n",
    "\n",
    "for my_Event in list_Events:\n",
    "    for my_Epoch_Length in test_Lengths:\n",
    "        for my_Overlap in overlaps:\n",
    "\n",
    "            # Create dataset for machine learning\n",
    "            labels = sliding_Window_Events(events, my_Epoch_Length, my_Overlap, 120)\n",
    "            event = dummy_Events(labels)\n",
    "            chosen_Event = event[my_Event] # 1-Stand_Free, 3-Lift_Squat, 5-Lower_Squat\n",
    "            current_Event = my_Event\n",
    "            #n = round(((number_Of_Samples - minL*sample_Rate)/(slide*sample_Rate)),0)-1\n",
    "            data_Frame = pd.DataFrame(sliding_Window(data, events, my_Epoch_Length, my_Overlap, 120))\n",
    "            data_Only = data_Frame[data_Frame.columns[2:]]\n",
    "\n",
    "            # Define the parameters\n",
    "            svcParameters = [{'gamma': 10.0 ** np.arange(-5, 4), 'C': 10.0 ** np.arange(-2, 7)}]\n",
    "            ldaParameters = [{'n_components' : [10, 20, 30, 40], 'solver': ['svd', 'lsqr', 'eigen']}]\n",
    "            knnParameters = [{'n_neighbors' : [5, 10, 15, 20]}]\n",
    "            #artParameters = [{'max_features' : [2, 4, 6, 8, 10]}]\n",
    "            #fParameters = [{'max_features': [\"sqrt\", \"log2\", None, 1], 'max_depth':[None, 15, 30, 50], 'min_samples_leaf': [2, 5, 10]}]\n",
    "\n",
    "            # Assemble default classifiers\n",
    "            svc = SVC(probability=True)\n",
    "            lda = LinearDiscriminantAnalysis()\n",
    "            knn = KNeighborsClassifier()\n",
    "            #cart = DecisionTreeClassifier()\n",
    "            nb = GaussianNB()\n",
    "            qda = QuadraticDiscriminantAnalysis()\n",
    "            lr = LogisticRegression()\n",
    "            #rf = RandomForestClassifier()\n",
    "\n",
    "            # Assemble grid parameter classifiers\n",
    "            svc2 = GridSearchCV(SVC(probability=True), svcParameters, cv=cv, scoring='accuracy')\n",
    "            lda2 = GridSearchCV(LinearDiscriminantAnalysis(), ldaParameters, cv=cv, scoring='accuracy')\n",
    "            knn2 = GridSearchCV(KNeighborsClassifier(), knnParameters, cv=cv, scoring='accuracy')\n",
    "            #cart2 = GridSearchCV(DecisionTreeClassifier(), cartParameters, cv=cv, scoring='accuracy')\n",
    "            #nb2 = GridSearchCV(GaussianNB(), nbParameters, cv=cv, scoring='accuracy')\n",
    "            #qda2 = GridSearchCV(QuadraticDiscriminantAnalysis(), qdaParameters, cv=cv, scoring='accuracy')\n",
    "            #rf2 = GridSearchCV(RandomForestClassifier(), rfParameters, cv=cv, scoring='accuracy')\n",
    "            \n",
    "            # Split the test and train datasets\n",
    "            for train_idx, test_idx in cv.split(labels):\n",
    "                y_train, y_test = chosen_Event.loc[train_idx], chosen_Event.loc[test_idx]\n",
    "                X_train, X_test = data_Only.loc[train_idx,:], data_Only.loc[test_idx,:]\n",
    "                \n",
    "            # Perform the machine learning\n",
    "            currentName = algorithms\n",
    "            #currentName = ['LDA']\n",
    "            #classifier = [ Pipeline([('KNN', knn2)]), Pipeline([('QDA', qda)]), Pipeline([('LR', lr)])]\n",
    "            classifier = [Pipeline([('LDA', lda)]), Pipeline([('KNN', knn)]), Pipeline([('NB', nb)]), Pipeline([('QDA', qda)]), Pipeline([('LR', lr)])]\n",
    "            #classifier = [Pipeline([('LDA', lda)])]\n",
    "            count = 0\n",
    "            for my_Classifier in classifier:\n",
    "                sAccuracy = cross_val_score(my_Classifier, X_train, y_train, scoring = 'accuracy', cv=cv, n_jobs=1)\n",
    "\n",
    "                # Printing the results\n",
    "                labels = chosen_Event\n",
    "                class_balance = np.mean(labels == labels[0])\n",
    "                class_balance = np.mean(labels)\n",
    "                class_balance = max(class_balance, 1. - class_balance)\n",
    "                y_pred = my_Classifier.fit(X_train, y_train).predict(X_test)\n",
    "                y_pred_prob = my_Classifier.predict_proba(X_test)\n",
    "                #y_pred_class = binarize(y_pred_prob, 0.5)[:,0] # Predict events labeled as 1 not 2 which in this case is zero.\n",
    "\n",
    "                rocTest = (1-y_test)+1\n",
    "                #auc = roc_auc_score(rocTest, y_pred_class)\n",
    "                tacc = accuracy_score(y_test, y_pred)\n",
    "                prec = precision_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "                kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "                names.append(currentName[count])\n",
    "                Event.append(current_Event)\n",
    "                Lengths.append(my_Epoch_Length)\n",
    "                Chance.append(class_balance)\n",
    "                Overlap.append(my_Overlap)\n",
    "                Accuracy.append(np.mean(sAccuracy))\n",
    "                TestAcc.append(tacc)\n",
    "                Precision.append(prec)\n",
    "                Recall.append(recall)\n",
    "                #AUC.append(auc)\n",
    "                Kappa.append(kappa)\n",
    "                count = count + 1\n",
    "                \n",
    "                header_Name = [my_Event, list(my_Classifier.named_steps.keys())[0], str(my_Epoch_Length), str(my_Overlap)]\n",
    "                current_Column = '_'.join(header_Name)\n",
    "\n",
    "            # Create a data frame that appends new columns\n",
    "            # Reprint the events\n",
    "            true_Events = y_test\n",
    "            \n",
    "\n",
    "#myData = {'Name' : names, 'Event': Event, 'Epochs' : Lengths, 'Chance' : Chance, 'Accuracy' : Accuracy, 'TestAcc' : TestAcc, 'Precision': Precision, 'Recall': Recall, 'AUC' : AUC, 'Kappa': Kappa}\n",
    "myData = {'Name' : names, 'Event': Event, 'Epochs' : Lengths, 'Overlap' : Overlap,  'Accuracy' : Accuracy, 'TestAcc' : TestAcc, 'Precision': Precision, 'Recall': Recall,  'Kappa': Kappa}\n",
    "\n",
    "test5 = pd.DataFrame(myData, columns = ['Name', 'Event', 'Epochs', 'Overlap', 'Accuracy', 'TestAcc', 'Precision', 'Recall', 'Kappa'])\n",
    "#test5.to_csv('testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Pipeline' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-205-a69a3b7f7952>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Pipeline' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "classifier[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-223-781f60392dc7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-223-781f60392dc7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    jupyter nbconvert --to html Lifiting%20Coach%20Preliminary%20Analysis.ipynb\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter nbconvert --to html Lifiting%20Coach%20Preliminary%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
